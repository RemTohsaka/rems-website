---
title: 'AGI Abuse and Exploits | Part One: Origins'
date: '2022-12-01'
tags: ['artificial-general-intelligence', 'safety', 'exploits', 'psychology']
readTime: 10 minutes
imgSrc: '/static/images/blog/hammer.png'
draft: false
summary: 'Part one in a series to understand, investigate, and mitigate abuse of artificial general intelligence.'
---

_This blog entry is the first in a multi-part series investigating the abuse and exploitation of artificial intelligence. In this entry, I hope to explore tool development, why abuse seems to occur in technology, and how moderating the development of a tool is a delicate matter._

___

<figure>
    <img src="/static/images/blog/hammer.png"
         alt="A hammer smashing rocks" />
    <figcaption>When you think of a hammer, do you think of building or smashing? <i>Disclaimer: this image was artificially generated using DALL-E 2.</i></figcaption>
</figure>

## Hammer and the Atomic Bomb: Repeat of History?

Consider the simple hammer: perhaps one of the first crafted tools developed by proto-humans. What led our ancestors to construct this tool? Was the first hammer a weapon of war, satisfying our primal instincts of survival and conquest? Or were our ancestors able to understand the creative potential of the hammer, using it to improve lives instead of injuring others’? 

Part of the development of a tool is the reciprocal process of discovering what activities suit it best. But what came first: destructive violence or constructive creativity? How many skulls were smashed under the fall of the hammer before its wielder considered other ways that same bludgeoning force could be applied?

### In some ways, the story of the hammer might be no different than that of modern technologies like nuclear physics. 

After all, the atomic bomb came well before much more ethical uses of the science: such as medicine or energy production. Even after all those centuries of evolution, development, ethics and philosophy, those scientists failed to have the restraint to cease the development of atomic weapons.

## Advent of AGI

As artificial general intelligence (AGI) rapidly approaches, I fear we are facing the same story. The potential for immoral applications of AGI are endless and terrifyingly real. A short list of scenarios that keep me awake at night include: 

- firearms perfectly modeled by an AGI, ready for crafting with an at-home 3D printer, and then used to commit a mass shooting,
- AGI traffic analysis and direction routing that unintentionally aids and abets human traffickers avoid authorities,
- cyber attacks on critical infrastructure or financial systems facilitated by AGI crafted code,
- AGI generated images and videos indistinguishable from reality that get used to foment riots, spread hatred, or even as evidence to wrongly convict a person.

Unfortunately, we already have ample evidence that current technologies are capable of accomplishing these scenarios, despite attempts to prevent them. Within hours of OpenAI’s [ChatGPT](https://openai.com/blog/chatgpt/) platform going public, users had already discovered ways to evade content restrictions to ask the AGI how to make incendiary devices. 

### And that is only just an example users were willing to share. 

I fear the other things they managed to trick the technology to generate for them, but knew not to widely gloat about publicly.

## Questioning Exploitation Motives

### Why were users so quick to abuse this new technology? 

Without delving into a dissertation of human psychology, it should be readily apparent to most that some people just enjoy exploiting things, especially technology. And by no means do I believe all of these individuals are inherently evil or wrong. Take video game speedrunning for example. Part of the allure of speedrunning a game is discovering a new cheat or broken mechanic to achieve a better time. Exploiting the game is completely innocent and wholesome fun. 

Could something as innocent as getting the world record in _Super Mario_ actually lead to some of the scenarios I mentioned above though? It is human nature to explore and experiment. Video games are just simulations, fun ways to mess around and satisfy curiosity. If you die in-game, so what? You can just respawn and try again.

Or, take another digital technology, social media, as an example. You can pretend to be whoever you want to be, just create a profile and go. You can communicate with others in ways you would never dare do in person. You can be a troll, throw insults, or discuss explicit topics. And if done with a minimal amount of forethought, you can do so with minimal to no impact to your in-person life. If you make a mistake or want to try something else you can just delete that profile and start anew.

In both examples, consequences are largely removed. 

### A detachment from responsibility, and to some degree, reality, results. 

This inherently detached relationship with consequence has made it difficult for some to determine when “the game” ends and the real world starts. I imagine the dopamine circuits in the brain responsible for rewarding a game exploit or berating someone on Twitter are no different than those firing when you trick [Midjourney](https://midjourney.com/home/?callbackUrl=%2Fapp%2F) to generate explicit porn. 

In other words, I think lots of people are hacking and abusing AGI simply because it is a challenge, a puzzle to be cracked, or perhaps satisfies that itch to cause chaos. To return to our story of the hammer, I think these people would be akin to those who went around smashing inanimate objects, causing havoc but not really being a danger to other life if you ignored them. Whether they actually meant harm is debatable; what is not debatable is their desire to determine what that new tool is capable of.

## Here Lie Dragons

What about those who actually seek to cause harm, though? Of course, the inherent answer is to pursue the age-old game of cat and mouse, developing restrictions, policies, and safety measures, only ultimately needing to constantly upgrade them. I believe there exists a better answer though, and I will explain that more in a future blog entry.

## Final Thoughts

Ultimately, I think those responsible for shepherding and ensuring the safety of AGI will face a paradoxical quandary. As a new tool, AGI deserves an open ability to discover what applications suit it best. Strict regulations might strangle progress. Naturally, there are obvious applications that should explicitly be banned from the outset. But what initially appears destructive might lead to life changing benefits for humanity. Figuring out the balance of moderation will require the utmost discernment.

Imagine if when the hammer was made our ancestors were horrified at its ability to be used as a weapon, and therefore completely discontinued its use. What catastrophic consequences might that have had? Perhaps those of our ancestors who blindly went smashing indiscriminately with a hammer struck the ground, split the earth, gained inspiration to develop the hoe, and revolutionized humanity with the advent of agriculture.

___

_Thank you so much for reading to the end of this article. I hope it inspired some new thoughts and questions for you. Next up, I will take a look at existing exploits, the linguistic and mathematical reasons behind them, and ways to potentially mitigate them._

_Until next time!_

_~Rem_
